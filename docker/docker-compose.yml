version: '3.1'
services:
  spark-master:
    image: scality/spark-master:hadoop2.8-2.2
    hostname: spark-master
#    depends_on:
#      - graphite
    ports:
      - "8080:8080"
      - "7077:7077"

  spark-worker:
    image: scality/spark-worker:hadoop2.8-2.2
    depends_on:
      - spark-master
#      - graphite
      - lb
    environment:
      SPARK_MASTER: spark://spark-master:7077
      CLUSTER_DNS: spark-worker
      INIT_REPLICATE: 1
      #  testing for now. use swarm secrets?
      AWS_ACCESS_KEY_ID: accessKey1
      AWS_SECRET_KEY: verySecretKey1

#  graphite:
#    image: scality/grafana_graphite
#    ports:
#      - '9000:80'
#      - '9081:81'
#      - '8125:8125/udp'
#      - '8126:8126'
#      - '2003:2003'
#      - '2004:2004'
#      - '7002:7002'
#      - '3000:3000'
#    volumes:
#      - ./tmp/data/whisper:/opt/graphite/storage/whisper
#      - ./tmp/data/grafana:/opt/grafana/data
#      - ./tmp/log/graphite:/opt/graphite/storage/log
#

  s3-data:
    build: ./images/S3/
    ports:
      - "9991:9991"
    environment:
      S3DATAPATH: /data
      LISTEN_ADDR: 0.0.0.0
    volumes:
      - "s3-data:/data:rw"
    command: npm run start_dataserver

  s3-metadata:
    build: ./images/S3/
    ports:
      - "9990:9990"
    environment:
      S3METADATAPATH: /metadata
      LISTEN_ADDR: 0.0.0.0
      RECORDLOG_ENABLED: "true"
    volumes:
      - 's3-metadata:/metadata:rw'
    command: npm run start_mdserver

  cache:
    image: redis:alpine
    ports:
      - "6379"

  s3-front:
    build: ./images/S3/
    ports:
      - "8000"
    environment:
      DATA_HOST: s3-data
      METADATA_HOST: s3-metadata
      REDIS_HOST: cache
      ENDPOINT: "localhost"
      RECORDLOG_ENABLED: "true"
    command: npm run start_s3server
    depends_on:
      - s3-data
      - s3-metadata
      - cache

  lb:
    image: zenko/loadbalancer
    ports:
      - "80:80"
    environment:
      LISTEN_PORT: 80
      UPSTREAM_SERVER: "s3-front:8000"
    depends_on:
      - s3-front


volumes:
  s3-data:
  s3-metadata: